{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test hdr_model\n",
    "'''\n",
    "\n",
    "from hdr_model import PLFourierNet, HDRDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ckpt_path = \"hdr_model/last.ckpt\"\n",
    "model = PLFourierNet(pos_embed=False)\n",
    "for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "    model.state_dict()[k].copy_(v)\n",
    "dataset = HDRDataset(side_length=256)\n",
    "loader = DataLoader(dataset, batch_size=1, pin_memory=True)\n",
    "ys_pred = []\n",
    "ys = []\n",
    "zs = np.arange(0.0, 0.05, 0.005)\n",
    "for i, batch in enumerate(loader):\n",
    "    x, y, _ = batch\n",
    "    z = torch.tensor([[zs[i]]]).float().to(model.device)\n",
    "    print(z)\n",
    "    x = x.float().to(model.device)\n",
    "    y = y.float().to(model.device)\n",
    "    z = z.float().to(model.device)\n",
    "    _ , y_pred = model(x, z)\n",
    "    loss = ((y_pred - y) ** 2).mean()\n",
    "    psnr = -10*torch.log10(loss)\n",
    "    print(psnr)\n",
    "    ys_pred.append(y_pred[0].detach().cpu().numpy().reshape(256,256))\n",
    "    ys.append(y[0].detach().cpu().numpy().reshape(256,256))\n",
    "\n",
    "length = len(dataset)\n",
    "fig1, axs1 = plt.subplots(1, length, figsize=(length * 4, 4))\n",
    "fig2, axs2 = plt.subplots(1, length, figsize=(length * 4, 4))\n",
    "\n",
    "for i, (y_, y_pred_) in enumerate(zip(ys, ys_pred)):\n",
    "    y_ = np.array(Image.open(dataset.images[i]).convert(\"L\"))\n",
    "    axs1[i].imshow(y_ , cmap='gray')\n",
    "    axs1[i].axis(\"off\")\n",
    "    axs2[i].imshow(y_pred_,  cmap='gray')\n",
    "    axs2[i].axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_hdr_model with slide bar\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_mul import PLFourierNet\n",
    "\n",
    "def show_image(z):\n",
    "    assert z>=0 and z<=5\n",
    "    ckpt_path = \"hdr_model/last.ckpt\"\n",
    "    model = PLFourierNet(pos_embed=False)\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1, 2).to(model.device)\n",
    "    z = torch.tensor([[z]]).float().to(model.device)\n",
    "    _ , y_pred = model(x, z)\n",
    "    y_pred = y_pred[0].detach().cpu().numpy().reshape(256,256)\n",
    "    plt.imshow(y_pred)\n",
    "    plt.show()\n",
    "\n",
    "contrast_slider = widgets.FloatSlider(value=0.001, min=0.0, max=0.06, step=0.001, description='latent')\n",
    "# display(contrast_slider)\n",
    "widgets.interactive(show_image, z=contrast_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test hdr_model with concatentation of [x,y,z]\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_xyz import PLFourierNet\n",
    "\n",
    "def show_image():\n",
    "    ckpt_path = \"hdr_xyz/last-v1.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(0.01, 0.02, 5),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,5,3).transpose(0,1)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.show()\n",
    "\n",
    "show_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test hdr_model with relu activation\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_relu import PLFourierNet\n",
    "\n",
    "def show_image():\n",
    "    ckpt_path = \"hdr_relu/last-v1.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(0.00, 0.04, 5),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,5,3).transpose(0,1)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.show()\n",
    "\n",
    "show_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test motion model xyt\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from motion import PLFourierNet\n",
    "import numpy as np\n",
    "\n",
    "def show_image():\n",
    "    ckpt_path = \"motion_xyt/last-v2.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    model = model.load_from_checkpoint(ckpt_path)\n",
    "    # for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "    #     model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    sequence_range=[5,20]\n",
    "    skip = 4\n",
    "    frames = len(np.arange(sequence_range[0], sequence_range[1], skip))\n",
    "\n",
    "    x = torch.stack(\n",
    "        torch.meshgrid(\n",
    "            [\n",
    "                torch.linspace(-1.0, 1.0, side_length),\n",
    "                torch.linspace(-1.0, 1.0, side_length),\n",
    "                torch.linspace(-0.01, 0.00, frames),\n",
    "            ]\n",
    "        ),\n",
    "        dim=-1,\n",
    "    ).view(-1,frames,3).transpose(0,1)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "show_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test motion model phase\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from motion_phase import PLFourierNet\n",
    "import numpy as np\n",
    "\n",
    "def show_image(z):\n",
    "    ckpt_path = \"motion_phase/last.ckpt\"\n",
    "    model = PLFourierNet(pos_embed = False)\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,2)\n",
    "    z = torch.tensor([[z]]).float().to(model.device)\n",
    "    main_representation, y_pred = model(x, z)\n",
    "   \n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    main_representation = (main_representation-main_representation.min())/(main_representation.max()-main_representation.min())\n",
    "\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    main_representation = main_representation.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "    plt.imshow(main_representation)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "contrast_slider = widgets.FloatSlider(value=0.000, min=0.0, max=0.1, step=0.005, description='latent')\n",
    "# display(contrast_slider)\n",
    "widgets.interactive(show_image, z=contrast_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test motion model phase\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from motion_phase import PLFourierNet\n",
    "import numpy as np\n",
    "\n",
    "def show_image(z):\n",
    "    ckpt_path = \"motion_phase/last-v1.ckpt\"\n",
    "    model = PLFourierNet(pos_embed = False)\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,2)\n",
    "    z = torch.tensor([[z]]).float().to(model.device)\n",
    "    main_representation, y_pred = model(x, z)\n",
    "   \n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    main_representation = (main_representation-main_representation.min())/(main_representation.max()-main_representation.min())\n",
    "\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    main_representation = main_representation.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "    plt.imshow(main_representation)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "contrast_slider = widgets.FloatSlider(value=0.000, min=0.0, max=0.05, step=0.005, description='latent')\n",
    "# display(contrast_slider)\n",
    "widgets.interactive(show_image, z=contrast_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a69566e79c408ba04234f36dbdbdcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='latent', max=15.0, step=0.3), Output()), _dom_classe…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test motion model phase\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from motion_modulate_posembed import PLFourierNet\n",
    "import numpy as np\n",
    "\n",
    "def show_image(z):\n",
    "    ckpt_path = \"/home/xxy/Documents/code/Fourier-Manifold/motion_phase_pos_embed/last-v12.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    \n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,2)\n",
    "    z1 = torch.sin(torch.linspace(-1.0, 1.0, side_length)*(2**(10))*np.pi+z/20*2*np.pi).view(-1,1)\n",
    "    z2 = torch.cos(torch.linspace(-1.0, 1.0, side_length)*(2**(10))*np.pi+z/20*2*np.pi).view(1,-1)\n",
    "    z = z1+z2\n",
    "    z = 0.01*z.view(-1,1)\n",
    "    x = x.unsqueeze(0)\n",
    "    z = z.unsqueeze(0)\n",
    "    main_representation, y_pred = model(x, z)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    main_representation = (main_representation-main_representation.min())/(main_representation.max()-main_representation.min())\n",
    "\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    main_representation = main_representation.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "    plt.imshow(main_representation)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "side_length = 64\n",
    "sequence_range=[15,175]\n",
    "skip = 10\n",
    "frames = len(np.arange(sequence_range[0], sequence_range[1], skip))\n",
    "contrast_slider = widgets.FloatSlider(value=0.000, min=0.0, max=frames-1, step=0.3, description='latent')\n",
    "# display(contrast_slider)\n",
    "widgets.interactive(show_image, z=contrast_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion_modulate_posembed import HDRDataModule\n",
    "kwargs = {\n",
    "        'project_name': 'motion_phase_pos_embed',\n",
    "        'batch_size': 10,\n",
    "        'side_length': 64,\n",
    "        'pos_embed': False,\n",
    "        'sequence_range': [15,75],\n",
    "        'skip': 10,\n",
    "        'motion_path': './motion_data/man'\n",
    "    }\n",
    "frames = len(np.arange(sequence_range[0], sequence_range[1], skip))\n",
    "loader = HDRDataModule(batch_size = kwargs['batch_size'], side_length=kwargs['side_length'], motion_path = kwargs['motion_path'], sequence_range=kwargs['sequence_range'], skip = kwargs['skip'])\n",
    "loader.setup()\n",
    "for d in loader.train_dataloader():\n",
    "    x, y_pred = d\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    fig, ax = plt.subplots(1,frames, figsize=(20,20))\n",
    "    for i,y in enumerate(y_pred):\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        ax[i].imshow(y)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
