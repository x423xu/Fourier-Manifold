{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test hdr_model\n",
    "'''\n",
    "\n",
    "from hdr_model import PLFourierNet, HDRDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "ckpt_path = \"hdr_model/last.ckpt\"\n",
    "model = PLFourierNet(pos_embed=False)\n",
    "for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "    model.state_dict()[k].copy_(v)\n",
    "dataset = HDRDataset(side_length=256)\n",
    "loader = DataLoader(dataset, batch_size=1, pin_memory=True)\n",
    "ys_pred = []\n",
    "ys = []\n",
    "zs = np.arange(0.0, 0.05, 0.005)\n",
    "for i, batch in enumerate(loader):\n",
    "    x, y, _ = batch\n",
    "    z = torch.tensor([[zs[i]]]).float().to(model.device)\n",
    "    print(z)\n",
    "    x = x.float().to(model.device)\n",
    "    y = y.float().to(model.device)\n",
    "    z = z.float().to(model.device)\n",
    "    _ , y_pred = model(x, z)\n",
    "    loss = ((y_pred - y) ** 2).mean()\n",
    "    psnr = -10*torch.log10(loss)\n",
    "    print(psnr)\n",
    "    ys_pred.append(y_pred[0].detach().cpu().numpy().reshape(256,256))\n",
    "    ys.append(y[0].detach().cpu().numpy().reshape(256,256))\n",
    "\n",
    "length = len(dataset)\n",
    "fig1, axs1 = plt.subplots(1, length, figsize=(length * 4, 4))\n",
    "fig2, axs2 = plt.subplots(1, length, figsize=(length * 4, 4))\n",
    "\n",
    "for i, (y_, y_pred_) in enumerate(zip(ys, ys_pred)):\n",
    "    y_ = np.array(Image.open(dataset.images[i]).convert(\"L\"))\n",
    "    axs1[i].imshow(y_ , cmap='gray')\n",
    "    axs1[i].axis(\"off\")\n",
    "    axs2[i].imshow(y_pred_,  cmap='gray')\n",
    "    axs2[i].axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_hdr_model with slide bar\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_mul import PLFourierNet\n",
    "\n",
    "def show_image(z):\n",
    "    assert z>=0 and z<=5\n",
    "    ckpt_path = \"hdr_model/last.ckpt\"\n",
    "    model = PLFourierNet(pos_embed=False)\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1, 2).to(model.device)\n",
    "    z = torch.tensor([[z]]).float().to(model.device)\n",
    "    _ , y_pred = model(x, z)\n",
    "    y_pred = y_pred[0].detach().cpu().numpy().reshape(256,256)\n",
    "    plt.imshow(y_pred)\n",
    "    plt.show()\n",
    "\n",
    "contrast_slider = widgets.FloatSlider(value=0.001, min=0.0, max=0.06, step=0.001, description='latent')\n",
    "# display(contrast_slider)\n",
    "widgets.interactive(show_image, z=contrast_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test hdr_model with concatentation of [x,y,z]\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_xyz import PLFourierNet\n",
    "\n",
    "def show_image():\n",
    "    ckpt_path = \"hdr_xyz/last-v1.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(0.01, 0.02, 5),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,5,3).transpose(0,1)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.show()\n",
    "\n",
    "show_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test hdr_model with relu activation\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from hdr_model_relu import PLFourierNet\n",
    "\n",
    "def show_image():\n",
    "    ckpt_path = \"hdr_relu/last-v1.ckpt\"\n",
    "    model = PLFourierNet()\n",
    "    for k,v in torch.load(ckpt_path, map_location='cpu')['state_dict'].items():\n",
    "        model.state_dict()[k].copy_(v)\n",
    "    side_length = 256\n",
    "    x = torch.stack(\n",
    "            torch.meshgrid(\n",
    "                [\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(-1.0, 1.0, side_length),\n",
    "                    torch.linspace(0.00, 0.04, 5),\n",
    "                ]\n",
    "            ),\n",
    "            dim=-1,\n",
    "        ).view(-1,5,3).transpose(0,1)\n",
    "    y_pred = model(x)\n",
    "    print(y_pred.shape)\n",
    "    y_pred = (y_pred-y_pred.min())/(y_pred.max()-y_pred.min())\n",
    "    for y in y_pred:\n",
    "        y = y.detach().cpu().numpy().reshape(side_length, side_length,3)\n",
    "        plt.imshow(y)\n",
    "        plt.show()\n",
    "\n",
    "show_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
